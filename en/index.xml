<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>François Hélénon</title><link>https://fhsup.github.io/en/</link><description>Recent content on François Hélénon</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>{{ YEAR }}-François Hélénon. Powered by [Hugo](https://gohugo.io/) and [Anatole](https://github.com/lxndrblz/anatole/) theme</copyright><atom:link href="https://fhsup.github.io/en/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://fhsup.github.io/en/publications/</link><pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate><guid>https://fhsup.github.io/en/publications/</guid><description>Articles Francois Helenon, Stephane Thiery, Eric Nyiri, and Olivier Gibaru. “Cognitive Architecture for Intuitive and Interactive Task Learning in Industrial Collaborative Robotics”. In: 2021 the 5th International Conference on Robotics, Control and Automation. New York, NY, USA: Association for Computing Machinery, Mar. 5, 2021, pp. 119–124. isbn: 978-1-4503-8748-4. DOI: 10.1145/3471985.3472385
Francois Helenon, Laurent Bimont, Eric Nyiri, Stephane Thiery, and Olivier Gibaru. “Learning prohibited and authorised grasping locations from a few demonstrations”.</description></item><item><title>Cognitive robotic architecture for learning from interaction</title><link>https://fhsup.github.io/en/projects/cognitive-robotic-architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fhsup.github.io/en/projects/cognitive-robotic-architecture/</guid><description>Collaborative work with Stéphane Thiery, Éric Nyiri and Olivier Gibaru
This work led to a publication as a conference article at ICRCA 2021.
In recent years, industrial robots have become more collaborative thanks to better sensors and higher level programming libraries. Yet, in real world scenarios, flexibility and interaction abilities of robots remains far from the natural interaction between two human co-workers. Thus, we are developing a smart robot agent (SRA) that can incrementally learn with a human in a teacher/learner setting called Interactive Task Learning (ITL).</description></item><item><title>Learning grasping from authorised and prohibited demonstrations</title><link>https://fhsup.github.io/en/projects/learning-grasping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fhsup.github.io/en/projects/learning-grasping/</guid><description>Work jointly done with Laurent Bimont, Stéphane Thiery, Éric Nyiri and Olivier Gibaru
This work led to a publication as a conference article at RO-MAN 2020.
Our motivation is to ease robots’ reconfiguration for pick and place tasks in an industrial context. We propose a fast learner neural network model trained from one or a few demonstrations in less than 5 minutes, able to efficiently predict grasping locations on a specific object.</description></item><item><title>Learning synergies between grasping and pushing in an autonomous way</title><link>https://fhsup.github.io/en/projects/learning-synergies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fhsup.github.io/en/projects/learning-synergies/</guid><description>With Laurent Bimont, Stéphane Thiery, Éric Nyiri and Olivier Gibaru.
The case of bin picking is a typical example of a task for which it can be difficult to explain in a procedural way how to perform it, even for a human. It is not easy to explain why a pile of objects should be scattered in a certain way rather than another.
Reinforcement learning is well suited to learn such a task autonomously.</description></item></channel></rss>